#!/usr/bin/env python3
"""
æ•¸æ“šåº«åŒæ­¥å·¥å…· - å°‡æ•¸æ“šåº«ä¸­çš„å·²åˆ†æè²¼æ–‡åŒæ­¥åˆ°Google Sheets
"""

import os
import sys
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from models.database import db_manager, AnalyzedPost, HumanFeedback
from clients.google_sheets_client import GoogleSheetsClient
from sqlalchemy.orm import sessionmaker
from sqlalchemy import func
import argparse
from datetime import datetime

class DatabaseSyncTool:
    def __init__(self):
        self.db = db_manager
        self.sheets_client = GoogleSheetsClient()
    
    def get_analyzed_posts_from_db(self, limit: int = None) -> list:
        """å¾æ•¸æ“šåº«ç²å–å·²åˆ†æçš„è²¼æ–‡"""
        session = self.db.get_session()
        try:
            print("ğŸ” å¾æ•¸æ“šåº«ç²å–å·²åˆ†æçš„è²¼æ–‡...")
            
            query = session.query(AnalyzedPost).order_by(AnalyzedPost.analyzed_at.desc())
            
            if limit:
                query = query.limit(limit)
            
            analyzed_posts = query.all()
            
            print(f"ğŸ“Š æ‰¾åˆ° {len(analyzed_posts)} æ¢è¨˜éŒ„")
            
            # è½‰æ›ç‚ºå­—å…¸æ ¼å¼
            posts_data = []
            for post in analyzed_posts:
                post_data = {
                    'collected_at': post.collected_at.strftime('%Y-%m-%d %H:%M:%S') if post.collected_at else '',
                    'platform': post.platform,
                    'author_username': post.author_username,
                    'author_display_name': post.author_display_name or '',
                    'post_time': post.post_time.strftime('%Y-%m-%d %H:%M:%S') if post.post_time else '',
                    'original_content': post.original_content or '',
                    'importance_score': post.importance_score,
                    'scoring_status': 'auto',
                    'human_score': '',  # å¾HumanFeedbackè¡¨ä¸­ç²å–
                    'post_url': post.post_url or '',
                    'post_id': post.original_post_id or str(post.id),
                    'category': post.category or '',
                    'notes': ''
                }
                posts_data.append(post_data)
            
            return posts_data
            
        except Exception as e:
            print(f"âŒ å¾æ•¸æ“šåº«ç²å–æ•¸æ“šå¤±æ•—: {e}")
            return []
        finally:
            session.close()
    
    def get_human_feedback_from_db(self) -> dict:
        """å¾æ•¸æ“šåº«ç²å–äººå·¥åé¥‹æ•¸æ“š"""
        session = self.db.get_session()
        try:
            feedbacks = session.query(HumanFeedback).all()
            
            # å»ºç«‹ analyzed_post_id åˆ° human_score çš„æ˜ å°„
            feedback_map = {}
            for feedback in feedbacks:
                feedback_map[feedback.analyzed_post_id] = {
                    'human_score': feedback.human_score,
                    'notes': feedback.reviewer_notes or feedback.feedback_reason or ''
                }
            
            print(f"ğŸ“ æ‰¾åˆ° {len(feedback_map)} æ¢äººå·¥åé¥‹è¨˜éŒ„")
            return feedback_map
            
        except Exception as e:
            print(f"âš ï¸  ç²å–äººå·¥åé¥‹å¤±æ•—: {e}")
            return {}
        finally:
            session.close()
    
    def merge_feedback_data(self, posts_data: list, feedback_map: dict) -> list:
        """åˆä½µè²¼æ–‡æ•¸æ“šå’Œåé¥‹æ•¸æ“š"""
        session = self.db.get_session()
        try:
            # å»ºç«‹ post_url åˆ° analyzed_post_id çš„æ˜ å°„
            analyzed_posts = session.query(AnalyzedPost).all()
            url_to_id_map = {post.post_url: post.id for post in analyzed_posts if post.post_url}
            
            # åˆä½µæ•¸æ“š
            for post_data in posts_data:
                post_url = post_data.get('post_url', '')
                if post_url in url_to_id_map:
                    analyzed_post_id = url_to_id_map[post_url]
                    if analyzed_post_id in feedback_map:
                        feedback = feedback_map[analyzed_post_id]
                        post_data['human_score'] = feedback['human_score']
                        post_data['notes'] = feedback['notes']
                        post_data['scoring_status'] = 'reviewed'
            
            return posts_data
            
        except Exception as e:
            print(f"âš ï¸  åˆä½µåé¥‹æ•¸æ“šå¤±æ•—: {e}")
            return posts_data
        finally:
            session.close()
    
    def get_existing_urls_from_sheets(self) -> set:
        """ç²å–Google Sheetsä¸­å·²å­˜åœ¨çš„URL"""
        try:
            from config import OUTPUT_SPREADSHEET_NAME, ALL_POSTS_WORKSHEET_NAME
            sheet = self.sheets_client.gc.open(OUTPUT_SPREADSHEET_NAME)
            
            try:
                worksheet = sheet.worksheet(ALL_POSTS_WORKSHEET_NAME)
                all_values = worksheet.get_all_values()
                
                if len(all_values) <= 1:
                    return set()
                
                headers = all_values[0]
                url_col_idx = headers.index('åŸå§‹è²¼æ–‡URL') if 'åŸå§‹è²¼æ–‡URL' in headers else -1
                
                if url_col_idx == -1:
                    return set()
                
                existing_urls = set()
                for row in all_values[1:]:
                    if len(row) > url_col_idx and row[url_col_idx]:
                        existing_urls.add(row[url_col_idx])
                
                print(f"ğŸ“Š Google Sheetsä¸­å·²æœ‰ {len(existing_urls)} æ¢è¨˜éŒ„")
                return existing_urls
                
            except Exception as e:
                print(f"âš ï¸  ç²å–ç¾æœ‰URLå¤±æ•—: {e}")
                return set()
                
        except Exception as e:
            print(f"âŒ é€£æ¥Google Sheetså¤±æ•—: {e}")
            return set()

    def sync_to_sheets(self, limit: int = None, force_overwrite: bool = False):
        """åŒæ­¥æ•¸æ“šåˆ°Google Sheets"""
        try:
            print("ğŸš€ é–‹å§‹åŒæ­¥æ•¸æ“šåˆ°Google Sheets...")
            
            # 1. ç²å–æ•¸æ“šåº«ä¸­çš„å·²åˆ†æè²¼æ–‡
            posts_data = self.get_analyzed_posts_from_db(limit)
            
            if not posts_data:
                print("âŒ æ²’æœ‰æ‰¾åˆ°å¯åŒæ­¥çš„æ•¸æ“š")
                return
            
            # 2. ç²å–äººå·¥åé¥‹æ•¸æ“š
            feedback_map = self.get_human_feedback_from_db()
            
            # 3. åˆä½µæ•¸æ“š
            merged_data = self.merge_feedback_data(posts_data, feedback_map)
            
            # 4. å¦‚æœä¸æ˜¯å¼·åˆ¶è¦†å¯«ï¼Œéæ¿¾æ‰å·²å­˜åœ¨çš„æ•¸æ“š
            if not force_overwrite:
                existing_urls = self.get_existing_urls_from_sheets()
                if existing_urls:
                    original_count = len(merged_data)
                    merged_data = [post for post in merged_data if post.get('post_url') not in existing_urls]
                    filtered_count = original_count - len(merged_data)
                    print(f"ğŸ” éæ¿¾æ‰ {filtered_count} æ¢å·²å­˜åœ¨çš„è¨˜éŒ„ï¼Œå‰©é¤˜ {len(merged_data)} æ¢æ–°è¨˜éŒ„")
                    
                    if not merged_data:
                        print("âœ… æ²’æœ‰æ–°æ•¸æ“šéœ€è¦åŒæ­¥")
                        return
            else:
                print("âš ï¸  å¼·åˆ¶è¦†å¯«æ¨¡å¼ï¼šå°‡æ¸…ç©ºç¾æœ‰å·¥ä½œè¡¨æ•¸æ“š")
                # é€™è£¡å¯ä»¥æ·»åŠ æ¸…ç©ºå·¥ä½œè¡¨çš„é‚è¼¯
                # self.clear_all_posts_sheet()
            
            # 5. å¯«å…¥Google Sheets
            print(f"ğŸ“¤ æ­£åœ¨å¯«å…¥ {len(merged_data)} æ¢æ–°è¨˜éŒ„åˆ°Google Sheets...")
            success = self.sheets_client.write_all_posts_with_scores(merged_data)
            
            if success:
                print("âœ… æ•¸æ“šåŒæ­¥æˆåŠŸï¼")
                print(f"ğŸ“Š å·²åŒæ­¥ {len(merged_data)} æ¢è¨˜éŒ„")
                
                # çµ±è¨ˆä¿¡æ¯
                with_human_feedback = sum(1 for post in merged_data if post.get('human_score'))
                with_ai_scores = sum(1 for post in merged_data if post.get('importance_score'))
                
                print(f"ğŸ“ˆ çµ±è¨ˆä¿¡æ¯:")
                print(f"   æœ‰AIè©•åˆ†çš„è²¼æ–‡: {with_ai_scores}")
                print(f"   æœ‰äººå·¥è©•åˆ†çš„è²¼æ–‡: {with_human_feedback}")
                print(f"   éœ€è¦äººå·¥è©•åˆ†çš„è²¼æ–‡: {with_ai_scores - with_human_feedback}")
                
            else:
                print("âŒ æ•¸æ“šåŒæ­¥å¤±æ•—")
                
        except Exception as e:
            print(f"âŒ åŒæ­¥éç¨‹ä¸­å‡ºéŒ¯: {e}")
    
    def preview_data(self, limit: int = 5):
        """é è¦½å°‡è¦åŒæ­¥çš„æ•¸æ“š"""
        print("ğŸ‘€ æ•¸æ“šé è¦½æ¨¡å¼")
        
        posts_data = self.get_analyzed_posts_from_db(limit)
        feedback_map = self.get_human_feedback_from_db()
        merged_data = self.merge_feedback_data(posts_data, feedback_map)
        
        if not merged_data:
            print("âŒ æ²’æœ‰æ‰¾åˆ°æ•¸æ“š")
            return
        
        print(f"\nğŸ“‹ å°‡åŒæ­¥ä»¥ä¸‹ {len(merged_data)} æ¢è¨˜éŒ„çš„é è¦½:\n")
        
        for i, post in enumerate(merged_data, 1):
            print(f"{i}. ã€{post['platform']}ã€‘@{post['author_username']}")
            print(f"   æ™‚é–“: {post['post_time']}")
            print(f"   AIè©•åˆ†: {post['importance_score']}")
            print(f"   äººå·¥è©•åˆ†: {post['human_score'] or 'æœªè©•åˆ†'}")
            print(f"   å…§å®¹é è¦½: {post['original_content'][:100]}...")
            print(f"   URL: {post['post_url']}")
            print("-" * 80)
    
    def check_sheets_connection(self):
        """æª¢æŸ¥Google Sheetsé€£æ¥"""
        try:
            print("ğŸ”— æª¢æŸ¥Google Sheetsé€£æ¥...")
            
            # å˜—è©¦ç²å–ç¾æœ‰æ•¸æ“š
            existing_posts = self.sheets_client.get_human_feedback_for_scoring(1)
            print("âœ… Google Sheetsé€£æ¥æ­£å¸¸")
            return True
            
        except Exception as e:
            print(f"âŒ Google Sheetsé€£æ¥å¤±æ•—: {e}")
            return False

def main():
    parser = argparse.ArgumentParser(description='æ•¸æ“šåº«åŒæ­¥å·¥å…·')
    parser.add_argument('--sync', action='store_true', help='åŒæ­¥æ•¸æ“šåˆ°Google Sheets')
    parser.add_argument('--preview', action='store_true', help='é è¦½å°‡è¦åŒæ­¥çš„æ•¸æ“š')
    parser.add_argument('--check-connection', action='store_true', help='æª¢æŸ¥Google Sheetsé€£æ¥')
    parser.add_argument('--limit', type=int, help='é™åˆ¶åŒæ­¥çš„è¨˜éŒ„æ•¸é‡')
    parser.add_argument('--force', action='store_true', help='å¼·åˆ¶è¦†å¯«ç¾æœ‰æ•¸æ“š')
    
    args = parser.parse_args()
    
    sync_tool = DatabaseSyncTool()
    
    if args.check_connection:
        sync_tool.check_sheets_connection()
    elif args.preview:
        sync_tool.preview_data(args.limit or 5)
    elif args.sync:
        sync_tool.sync_to_sheets(args.limit, args.force)
    else:
        print("ğŸ“Š æ•¸æ“šåº«åŒæ­¥å·¥å…·")
        print("\nğŸ“‹ å¯ç”¨å‘½ä»¤:")
        print("   --check-connection  æª¢æŸ¥Google Sheetsé€£æ¥")
        print("   --preview          é è¦½å°‡è¦åŒæ­¥çš„æ•¸æ“š")
        print("   --sync             åŒæ­¥æ•¸æ“šåˆ°Google Sheets")
        print("   --limit N          é™åˆ¶è™•ç†çš„è¨˜éŒ„æ•¸é‡")
        print("   --force            å¼·åˆ¶è¦†å¯«ç¾æœ‰æ•¸æ“š")
        print("\nğŸ’¡ å»ºè­°å·¥ä½œæµç¨‹:")
        print("   1. python sync_database_to_sheets.py --check-connection")
        print("   2. python sync_database_to_sheets.py --preview")
        print("   3. python sync_database_to_sheets.py --sync")

if __name__ == "__main__":
    main()